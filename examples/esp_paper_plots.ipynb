{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESP Paper\n",
    "\n",
    "Here is all the code that went into the paper and everything required to create the plots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import esp\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from esp.lsst_utils import Bandpass\n",
    "from esp.lsst_utils import BandpassDict\n",
    "from esp.lsst_utils import Sed\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import binned_statistic, trim_mean\n",
    "from sklearn.decomposition import PCA as sklPCA\n",
    "from esp.spec_utils import specUtils\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `sims_sed_library` and remove duplicate SEDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getenv('HOME')\n",
    "galaxy_dir = '%s/lsst/DarwinX86/sims_sed_library/2016.01.26/galaxySED/' % home_dir\n",
    "pca_obj = esp.pcaSED()\n",
    "pca_obj.load_full_spectra(galaxy_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_spec_list = []\n",
    "i = 0\n",
    "for spec_obj in pca_obj.spec_list_orig:\n",
    "    if i % 100 == 0:\n",
    "        print('On Spectrum %i out of %i' % (i, len(pca_obj.spec_list_orig)))\n",
    "    j = 0\n",
    "    keep = True\n",
    "    for new_spec_obj in new_spec_list:\n",
    "        spec_flux = new_spec_obj.flambda\n",
    "        if np.array_equal(np.array(spec_obj.flambda), spec_flux):\n",
    "            #print(i,j) ## Uncomment to see which SEDs match to one another\n",
    "            keep = False\n",
    "        elif len(np.where(np.isclose(np.array(spec_obj.flambda), \n",
    "                                     spec_flux, atol=0., rtol=1e-5) == True)[0]) >= (0.9*6900):\n",
    "            #print(i,j) ## Uncomment to see which SEDs match to one another\n",
    "            keep = False\n",
    "        else:\n",
    "            j+=1\n",
    "    \n",
    "    if keep is True:\n",
    "        new_spec_list.append(spec_obj)\n",
    "    i += 1\n",
    "print(len(new_spec_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the resolution of the spectra and what do they look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = new_spec_list[0].wavelen[1:] - new_spec_list[0].wavelen[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_spec_list[190].name)\n",
    "print(new_spec_list[240].name)\n",
    "print(new_spec_list[360].name)\n",
    "print(new_spec_list[686].name)\n",
    "print(np.where(new_spec_list[0].wavelen <= 2400.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(14,12))\n",
    "\n",
    "fig.text(0.55, -0.02, 'Wavelength (nm)', ha='center', size=32)\n",
    "\n",
    "ax[0].plot(new_spec_list[0].wavelen[:6561], \n",
    "           (new_spec_list[190].flambda/np.max(new_spec_list[190].flambda))[:6561], lw=4,\n",
    "          label='Burst SF, 5.0E9 Years, Z=Z_sun')\n",
    "ax[0].plot(new_spec_list[0].wavelen[:6561], \n",
    "           (new_spec_list[240].flambda/np.max(new_spec_list[240].flambda))[:6561], lw=4,\n",
    "          label='Constant SF, 1.0E9 Years, Z=0.005*Z_sun')\n",
    "ax[0].plot(new_spec_list[0].wavelen[:6561], \n",
    "           (new_spec_list[360].flambda/np.max(new_spec_list[360].flambda))[:6561], lw=4,\n",
    "          label='Exponential SF, 1.5E6 Years, Z=0.02*Z_sun')\n",
    "ax[0].plot(new_spec_list[0].wavelen[:6561], \n",
    "           (new_spec_list[686].flambda/np.max(new_spec_list[686].flambda))[:6561], lw=4,\n",
    "          label='Instantaneous SF, 3.2E8 Years, Z=2.5*Z_sun')\n",
    "ax[0].set_ylabel('Scaled Flux', size=24)\n",
    "ax[0].set_title('Example Spectra', size=24)\n",
    "ax[0].legend(fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "ax[1].plot(new_spec_list[0].wavelen[:6561], resolution[:6561], label='Resolution', lw=6)\n",
    "ax[1].set_title('Resolution', size=24)\n",
    "ax[1].set_ylabel('Resolution (nm)', size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Bandpasses and Create Artificial Bandpasses beyond the ugrizy of LSST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandpass_dir = '%s/lsst/DarwinX86/throughputs/2016.12.13/baseline/' % home_dir\n",
    "filters = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "bandpass_dict = BandpassDict.loadTotalBandpassesFromFiles(bandpassNames = filters,\n",
    "                                                          bandpassDir = bandpass_dir,\n",
    "                                                          bandpassRoot = 'total_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_sb_1 = np.zeros(13000)\n",
    "blue_sb_1[0:500] += 1.\n",
    "#blue_sb_1[:100] += 1.\n",
    "blue_sb_2 = np.zeros(13000)\n",
    "blue_sb_2[500:1000] += 1.\n",
    "#blue_sb_2[100:200] += 1.\n",
    "\n",
    "blue_sb_3 = np.zeros(13000)\n",
    "blue_sb_3[1000:1500] += 1.\n",
    "blue_sb_4 = np.zeros(13000)\n",
    "blue_sb_4[1500:2000] += 1.\n",
    "\n",
    "red_sb_1 = np.zeros(13000)\n",
    "red_sb_1[11000:11500] += 1.\n",
    "#red_sb_1[1100:1200] += 1.\n",
    "red_sb_2 = np.zeros(13000)\n",
    "red_sb_2[11500:12000] += 1.\n",
    "#red_sb_2[1200:] += 1.\n",
    "\n",
    "red_sb_3 = np.zeros(13000)\n",
    "red_sb_3[12000:12500] += 1.\n",
    "red_sb_4 = np.zeros(13000)\n",
    "red_sb_4[12500:13000] += 1.\n",
    "\n",
    "blue_bandpass_1 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=blue_sb_1)\n",
    "blue_bandpass_2 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=blue_sb_2)\n",
    "blue_bandpass_3 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=blue_sb_3)\n",
    "blue_bandpass_4 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=blue_sb_4)\n",
    "red_bandpass_1 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=red_sb_1)\n",
    "red_bandpass_2 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=red_sb_2)\n",
    "red_bandpass_3 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=red_sb_3)\n",
    "red_bandpass_4 = Bandpass(wavelen=np.arange(100, 1400, .1), sb=red_sb_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_bandpass_dict = BandpassDict([\n",
    "                                  blue_bandpass_1, blue_bandpass_3, \n",
    "                                  #blue_bandpass_3, blue_bandpass_4,\n",
    "                                  bandpass_dict['u'], bandpass_dict['g'], \n",
    "                                  bandpass_dict['r'], bandpass_dict['i'], bandpass_dict['z'], \n",
    "                                  bandpass_dict['y'], #red_bandpass_1, red_bandpass_2, \n",
    "                                  red_bandpass_2, red_bandpass_4\n",
    "                                 ],\n",
    "                                ['blue_1', #'blue_2', \n",
    "                                 'blue_3', #'blue_4', \n",
    "                                 'u', 'g', 'r', 'i', 'z', 'y', \n",
    "                                 'red_2',#'red_2', \n",
    "                                 'red_4', #'red_4'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_obj.spec_list_orig = new_spec_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_training_and_test_set(pca_obj, bandpass_dict, min_wavelen, max_wavelen, \n",
    "                                 rand_print=False):\n",
    "    rand_choice = np.random.choice(np.arange(len(pca_obj.spec_list_orig)), size=60, replace=False)\n",
    "    if rand_print is True:\n",
    "        print(rand_choice)\n",
    "    sed_list = []\n",
    "    names = []\n",
    "    for row in rand_choice:\n",
    "        #print row\n",
    "        sed_list.append(pca_obj.spec_list_orig[row])\n",
    "        names.append(sed_list[-1].name)\n",
    "    training_list = sed_list[:10]\n",
    "    training_names = names[:10]\n",
    "    test_list = sed_list[10:]\n",
    "    test_names = names[10:]\n",
    "    \n",
    "    training_colors = []\n",
    "    test_colors = []\n",
    "    \n",
    "    for train_sed in training_list:\n",
    "        \n",
    "        train_mags = bandpass_dict.magListForSed(train_sed)\n",
    "        \n",
    "        colors = [train_mags[x] - train_mags[x+1] for x in range(len(train_mags)-1)]\n",
    "        training_colors.append(colors)        \n",
    "        \n",
    "    \n",
    "    min_idx = np.where(test_list[0].wavelen < min_wavelen)[0][-1] + 1\n",
    "    max_idx = np.where(test_list[0].wavelen > max_wavelen)[0][0]\n",
    "    test_fluxes = []\n",
    "    \n",
    "    for test_sed in test_list:\n",
    "        \n",
    "        test_fluxes.append(pca_obj.scale_spectrum(test_sed.flambda[min_idx:max_idx]))\n",
    "        \n",
    "        test_mags = bandpass_dict.magListForSed(test_sed)\n",
    "        \n",
    "        colors = [test_mags[x] - test_mags[x+1] for x in range(len(test_mags)-1)]\n",
    "        test_colors.append(colors)\n",
    "    test_colors = np.array(test_colors)\n",
    "    test_fluxes = np.array(test_fluxes)\n",
    "        \n",
    "    return training_colors, training_list, training_names, test_list, test_names, test_fluxes, test_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def linear_interpolation_spectra(training_colors, test_colors, training_spectra, \n",
    "                                 bandpass_dict, min_wavelen, max_wavelen):\n",
    "    lin_reg = LinearRegression()\n",
    "    su = specUtils()\n",
    "    \n",
    "    training_fluxes = []\n",
    "    for train_spec in training_spectra:\n",
    "        training_fluxes.append(train_spec.flambda)\n",
    "        \n",
    "    min_idx = np.where(training_spectra[0].wavelen < min_wavelen)[0][-1] + 1\n",
    "    max_idx = np.where(training_spectra[0].wavelen > max_wavelen)[0][0]\n",
    "        \n",
    "    lin_reg.fit(training_colors, training_fluxes)\n",
    "    test_list = lin_reg.predict(test_colors)\n",
    "    test_fluxes = []\n",
    "    test_colors = []\n",
    "    for test_flux in test_list:\n",
    "        \n",
    "        test_sed = Sed()\n",
    "        for test_flux_bin in range(len(test_flux)):\n",
    "            if test_flux[test_flux_bin] < 0.:\n",
    "                test_flux[test_flux_bin] = 0.\n",
    "                \n",
    "        test_sed.setSED(wavelen=training_spectra[0].wavelen[min_idx:max_idx], flambda=test_flux[min_idx:max_idx])\n",
    "        \n",
    "        test_fluxes.append(su.scale_spectrum(test_sed.flambda))\n",
    "        \n",
    "        test_mags = bandpass_dict.magListForSed(test_sed)\n",
    "        \n",
    "        colors = [test_mags[x] - test_mags[x+1] for x in range(len(test_mags)-1)]\n",
    "        test_colors.append(colors)\n",
    "    \n",
    "    return test_fluxes, test_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dist_bins(distances, results, n_bins):\n",
    "    #bin_vals = [(float(i)/n_bins)*np.max(distances) for i in range(n_bins)]\n",
    "    bin_vals = [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.55, \n",
    "                0.6, 0.7, 0.8, 0.9, 1.0, 1.2, 1.4, 1.6]\n",
    "    bin_vals.append(float(np.max(distances)))\n",
    "    idx_sort = distances.argsort()\n",
    "    dist_sort = distances[idx_sort]\n",
    "    #z_true_sort = z_true[idx_sort]\n",
    "    results_sort = results[idx_sort]\n",
    "    idx_bins = dist_sort.searchsorted(bin_vals)\n",
    "    #print idx_bins\n",
    "    results_binned = [results_sort[idx_bins[i]:idx_bins[i+1]] for i in range(len(bin_vals)-1)]\n",
    "    return bin_vals, results_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_dist_results(results_binned):\n",
    "    mean_results = [np.mean(x) for x in results_binned]\n",
    "    return np.array(mean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_dist_results(results_binned):\n",
    "    median_results = [np.median(x) for x in results_binned]\n",
    "    return np.array(median_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1: Optical Wavelengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "li_flux_results = np.zeros((25000, 6071))\n",
    "nn_flux_u_results = np.zeros((25000, 6071))\n",
    "#nn_flux_2u_results = np.zeros((25000, 6071))\n",
    "nn_flux_2d_results = np.zeros((25000, 6071))\n",
    "#nn_flux_4u_results = np.zeros((25000, 6071))\n",
    "#nn_flux_4d_results = np.zeros((25000, 6071))\n",
    "gp_exp_flux_results = np.zeros((25000, 6071))\n",
    "gp_sq_exp_flux_results = np.zeros((25000, 6071))\n",
    "gp_matern_32_flux_results = np.zeros((25000, 6071))\n",
    "gp_matern_52_flux_results = np.zeros((25000, 6071))\n",
    "\n",
    "training_colors_full = []\n",
    "training_coeffs_full = []\n",
    "training_eigenspectra = []\n",
    "training_meanspec = []\n",
    "\n",
    "test_colors_full = []\n",
    "\n",
    "test_exp_params = []\n",
    "test_sq_exp_params = []\n",
    "test_matern_32_params = []\n",
    "test_matern_52_params = []\n",
    "\n",
    "distances_all = []\n",
    "\n",
    "test_flux_orig = []\n",
    "flux_errors_full = []\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 299.\n",
    "max_wavelen = 1200.\n",
    "n_colors = 5\n",
    "n_comps = 9\n",
    "\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(training_colors)\n",
    "    distance, idx = nbrs.kneighbors(test_colors)\n",
    "    distances_all.append(np.ravel(distance))\n",
    "    \n",
    "    #print 'Linear Interp'\n",
    "    li_spec, li_colors = linear_interpolation_spectra(colors, test_colors, new_pca_obj.spec_list_orig, \n",
    "                                                      bandpass_dict, min_wavelen, max_wavelen)\n",
    "    li_flux_results[i*50:(i+1)*50] = np.abs(np.array((li_spec - test_fluxes)/test_fluxes))\n",
    "    \n",
    "    #print 'Nearest Neighbor Results'\n",
    "    nn_obj = esp.nearestNeighborEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    nn_spec = nn_obj.nn_predict(1)\n",
    "    nn_flux_u_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "\n",
    "    #nn_spec = nn_obj.nn_predict(2)\n",
    "    #nn_flux_2u_results.append(np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes)))\n",
    "    nn_spec = nn_obj.nn_predict(2, knr_args=dict(weights='distance'))\n",
    "    nn_flux_2d_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "\n",
    "    #nn_spec = nn_obj.nn_predict(4)\n",
    "    #nn_flux_4u_results.append(np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes)))\n",
    "    #nn_spec = nn_obj.nn_predict(4, knr_args=dict(weights='distance'))\n",
    "    \n",
    "    #print 'Gaussian Process Results'\n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    gp_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((gp_spec.reconstruct_spectra(n_comps) - test_fluxes)/test_fluxes))#, \n",
    "    test_exp_params.append(gp_spec.params)\n",
    "    \n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('sq_exp', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_sq_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))#, \n",
    "    test_sq_exp_params.append(gp_spec.params)\n",
    "        \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_32', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_32_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_32_params.append(gp_spec.params)\n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_52', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_52_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_52_params.append(gp_spec.params)\n",
    "    \n",
    "    training_colors_full.append(colors)\n",
    "    test_colors_full.append(test_colors)\n",
    "\n",
    "\n",
    "test_colors_full = np.array(test_colors_full)\n",
    "\n",
    "training_colors_full = np.array(training_colors_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating overall means\")\n",
    "\n",
    "gp_exp_flux_mean = np.mean(gp_exp_flux_results)\n",
    "nn_flux_u_mean = np.mean(nn_flux_u_results)\n",
    "gp_sq_exp_flux_mean = np.mean(gp_sq_exp_flux_results)\n",
    "nn_flux_2d_mean = np.mean(nn_flux_2d_results)\n",
    "#nn_flux_2u_mean = np.mean(nn_flux_2u_results)\n",
    "#nn_flux_4d_mean = np.mean(nn_flux_4d_results)\n",
    "#nn_flux_4u_mean = np.mean(nn_flux_4u_results)\n",
    "li_flux_mean = np.mean(li_flux_results)\n",
    "gp_matern_32_flux_mean = np.mean(gp_matern_32_flux_results)\n",
    "gp_matern_52_flux_mean = np.mean(gp_matern_52_flux_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_spec = np.mean(gp_exp_flux_results, axis=0)\n",
    "gp_sq_exp_flux_mean_spec = np.mean(gp_sq_exp_flux_results, axis=0)\n",
    "nn_flux_u_mean_spec = np.mean(nn_flux_u_results, axis=0)\n",
    "nn_flux_2d_mean_spec = np.mean(nn_flux_2d_results, axis=0)\n",
    "#nn_flux_2u_mean_spec = np.mean(nn_flux_2u_results, axis=0)\n",
    "#nn_flux_4d_mean_spec = np.mean(nn_flux_4d_results, axis=0)\n",
    "#nn_flux_4u_mean_spec = np.mean(nn_flux_4u_results, axis=0)\n",
    "li_flux_mean_spec = np.mean(li_flux_results, axis=0)\n",
    "gp_matern_32_flux_mean_spec = np.mean(gp_matern_32_flux_results, axis=0)\n",
    "gp_matern_52_flux_mean_spec = np.mean(gp_matern_52_flux_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_dist = np.mean(gp_exp_flux_results, axis=1)\n",
    "gp_sq_exp_flux_mean_dist = np.mean(gp_sq_exp_flux_results, axis=1)\n",
    "gp_matern_32_flux_mean_dist = np.mean(gp_matern_32_flux_results, axis=1)\n",
    "gp_matern_52_flux_mean_dist = np.mean(gp_matern_52_flux_results, axis=1)\n",
    "nn_flux_u_mean_dist = np.mean(nn_flux_u_results, axis=1)\n",
    "nn_flux_2d_mean_dist = np.mean(nn_flux_2d_results, axis=1)\n",
    "li_flux_mean_dist = np.mean(li_flux_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exponential Kernel 1st 3\n",
    "print('Exponential')\n",
    "print(np.mean(np.array(np.exp(test_exp_params))[:, 0], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_exp_params))[:, 1], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_exp_params))[:, 2], axis=0)*np.array([5., 1.]))\n",
    "#Squared Exponential Kernel 1st 3\n",
    "print('Squared Exponential')\n",
    "print(np.mean(np.array(np.exp(test_sq_exp_params))[:, 0], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_sq_exp_params))[:, 1], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_sq_exp_params))[:, 2], axis=0)*np.array([5., 1.]))\n",
    "#Matern 3/2 Kernel 1st 3\n",
    "print('Matern 3/2')\n",
    "print(np.mean(np.array(np.exp(test_matern_32_params))[:, 0], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_matern_32_params))[:, 1], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_matern_32_params))[:, 2], axis=0)*np.array([5., 1.]))\n",
    "#Matern 5/2 Kernel 1st 3\n",
    "print('Matern 5/2')\n",
    "print(np.mean(np.array(np.exp(test_matern_52_params))[:, 0], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_matern_52_params))[:, 1], axis=0)*np.array([5., 1.]))\n",
    "print(np.mean(np.array(np.exp(test_matern_52_params))[:, 2], axis=0)*np.array([5., 1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_exp_flux_mean)\n",
    "print(gp_sq_exp_flux_mean)\n",
    "print(gp_matern_32_flux_mean)\n",
    "print(gp_matern_52_flux_mean)\n",
    "print(nn_flux_u_mean)\n",
    "print(nn_flux_2d_mean)\n",
    "print(li_flux_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_exp_argsort = np.argsort(gp_exp_flux_mean_dist)\n",
    "gp_exp_trim_25_idx = gp_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_exp_flux_mean_dist[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_sq_exp_argsort = np.argsort(gp_sq_exp_flux_mean_dist)\n",
    "gp_sq_exp_trim_25_idx = gp_sq_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_sq_exp_flux_mean_dist[gp_sq_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_32_argsort = np.argsort(gp_matern_32_flux_mean_dist)\n",
    "gp_matern_32_trim_25_idx = gp_matern_32_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_32_flux_mean_dist[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_52_argsort = np.argsort(gp_matern_52_flux_mean_dist)\n",
    "gp_matern_52_trim_25_idx = gp_matern_52_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_52_flux_mean_dist[gp_matern_52_trim_25_idx]))\n",
    "\n",
    "nn_flux_u_argsort = np.argsort(nn_flux_u_mean_dist)\n",
    "nn_flux_u_trim_25_idx = nn_flux_u_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_u_mean_dist[nn_flux_u_trim_25_idx]))\n",
    "\n",
    "nn_flux_2d_argsort = np.argsort(nn_flux_2d_mean_dist)\n",
    "nn_flux_2d_trim_25_idx = nn_flux_2d_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_2d_mean_dist[nn_flux_2d_trim_25_idx]))\n",
    "\n",
    "li_flux_argsort = np.argsort(li_flux_mean_dist)\n",
    "li_flux_trim_25_idx = li_flux_argsort[6250:-6250]\n",
    "print(np.mean(li_flux_mean_dist[li_flux_trim_25_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Wavelength (nm)', size=32)\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22) \n",
    "\n",
    "fig.add_subplot(1,1,1)\n",
    "plt.plot(new_pca_obj.wavelengths, nn_flux_u_mean_spec, label='Nearest')\n",
    "plt.plot(new_pca_obj.wavelengths, nn_flux_2d_mean_spec, label='2 Nearest, Distance')\n",
    "plt.plot(new_pca_obj.wavelengths, li_flux_mean_spec, label='Linear Estimation')\n",
    "plt.plot(new_pca_obj.wavelengths, gp_sq_exp_flux_mean_spec, label='GP w/ Sq. Exp. Kernel')\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_52_flux_mean_spec, label='GP w/ Matern-5/2 Kernel')\n",
    "\n",
    "\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('Mean Fractional Flux Residuals', size=24)\n",
    "plt.ylabel('Mean Fractional Residuals', size=22)\n",
    "plt.xlim(300, 1200)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_xlabel('Wavelength (nm)', size=32)\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22)\n",
    "\n",
    "fig.add_subplot(1,1,1)\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_52_flux_mean_spec/nn_flux_2d_mean_spec, label='GP with Matern-5/2 / 2 NN')\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_52_flux_mean_spec/li_flux_mean_spec, label='GP with Matern-5/2 / Linear')\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('Ratio of Mean Fractional Residuals', size=24)\n",
    "plt.ylabel('Ratio of Mean Frac. Resid.', size=22)\n",
    "plt.hlines(1.0, 300, 1200, colors='k', linestyles='dashed', lw=6)\n",
    "plt.xlim(300, 1200)\n",
    "plt.ylim(0.1, 1.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(14,12))\n",
    "\n",
    "fig.text(0.55, -0.02, 'Wavelength (nm)', ha='center', size=32)\n",
    "fig.text(-0.02, 0.5, 'Flux (scaled)', va='center', rotation='vertical', size=32)\n",
    "\n",
    "ax[0].plot(new_pca_obj.wavelengths, new_pca_obj.mean_spec, label='Mean Spectrum')\n",
    "ax[0].set_title('Mean Spectrum', size=24)\n",
    "\n",
    "ax[1].plot(new_pca_obj.wavelengths, new_pca_obj.eigenspectra[0], label='1st Eigenspectrum')\n",
    "\n",
    "ax[1].plot(new_pca_obj.wavelengths, new_pca_obj.eigenspectra[1], label='2nd Eigenspectrum')\n",
    "\n",
    "ax[1].plot(new_pca_obj.wavelengths, new_pca_obj.eigenspectra[2], label='3rd Eigenspectrum')\n",
    "plt.legend(fontsize=24)\n",
    "plt.title('1st 3 Eigenspectra', size=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with larger part of spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "li_flux_results = np.zeros((25000, 6431))\n",
    "nn_flux_u_results = np.zeros((25000, 6431))\n",
    "nn_flux_2d_results = np.zeros((25000, 6431))\n",
    "gp_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_sq_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_32_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_52_flux_results = np.zeros((25000, 6431))\n",
    "\n",
    "training_colors_full = []\n",
    "training_coeffs_full = []\n",
    "training_eigenspectra = []\n",
    "training_meanspec = []\n",
    "\n",
    "test_colors_full = []\n",
    "test_exp_params = []\n",
    "test_sq_exp_params = []\n",
    "test_matern_32_params = []\n",
    "test_matern_52_params = []\n",
    "distances_all = []\n",
    "\n",
    "test_flux_orig = []\n",
    "flux_errors_full = []\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 99.\n",
    "max_wavelen = 2400.\n",
    "n_colors = 5\n",
    "n_comps = 9\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "    \n",
    "    #print 'Linear Interp'\n",
    "    li_spec, li_colors = linear_interpolation_spectra(colors, test_colors, new_pca_obj.spec_list_orig, \n",
    "                                                      bandpass_dict, min_wavelen, max_wavelen)\n",
    "    li_flux_results[i*50:(i+1)*50] = np.abs(np.array((li_spec - test_fluxes)/test_fluxes))\n",
    "    \n",
    "    #print 'Nearest Neighbor Results'\n",
    "    nn_obj = esp.nearestNeighborEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    nn_spec = nn_obj.nn_predict(1)\n",
    "    nn_flux_u_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "\n",
    "    nn_spec = nn_obj.nn_predict(2, knr_args=dict(weights='distance'))\n",
    "    nn_flux_2d_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "    \n",
    "    #print 'Gaussian Process Results'\n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    gp_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((gp_spec.reconstruct_spectra(n_comps) - test_fluxes)/test_fluxes))#, \n",
    "    test_exp_params.append(gp_spec.params)\n",
    "    \n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('sq_exp', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_sq_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))#, \n",
    "    test_sq_exp_params.append(gp_spec.params)\n",
    "        \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_32', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_32_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_32_params.append(gp_spec.params)\n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_52', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_52_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_52_params.append(gp_spec.params)\n",
    "    \n",
    "    training_colors_full.append(colors)\n",
    "    test_colors_full.append(test_colors)\n",
    "\n",
    "\n",
    "test_colors_full = np.array(test_colors_full)\n",
    "\n",
    "training_colors_full = np.array(training_colors_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating overall means\")\n",
    "\n",
    "gp_exp_flux_mean = np.mean(gp_exp_flux_results)\n",
    "nn_flux_u_mean = np.mean(nn_flux_u_results)\n",
    "gp_sq_exp_flux_mean = np.mean(gp_sq_exp_flux_results)\n",
    "nn_flux_2d_mean = np.mean(nn_flux_2d_results)\n",
    "li_flux_mean = np.mean(li_flux_results)\n",
    "gp_matern_32_flux_mean = np.mean(gp_matern_32_flux_results)\n",
    "gp_matern_52_flux_mean = np.mean(gp_matern_52_flux_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_exp_flux_mean)\n",
    "print(gp_sq_exp_flux_mean)\n",
    "print(gp_matern_32_flux_mean)\n",
    "print(gp_matern_52_flux_mean)\n",
    "print(nn_flux_u_mean)\n",
    "print(nn_flux_2d_mean)\n",
    "print(li_flux_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_dist_2 = np.mean(gp_exp_flux_results, axis=1)\n",
    "gp_sq_exp_flux_mean_dist_2 = np.mean(gp_sq_exp_flux_results, axis=1)\n",
    "nn_flux_u_mean_dist_2 = np.mean(nn_flux_u_results, axis=1)\n",
    "nn_flux_2d_mean_dist_2 = np.mean(nn_flux_2d_results, axis=1)\n",
    "li_flux_mean_dist_2 = np.mean(li_flux_results, axis=1)\n",
    "gp_matern_32_flux_mean_dist_2 = np.mean(gp_matern_32_flux_results, axis=1)\n",
    "gp_matern_52_flux_mean_dist_2 = np.mean(gp_matern_52_flux_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_exp_argsort = np.argsort(gp_exp_flux_mean_dist_2)\n",
    "gp_exp_trim_25_idx = gp_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_exp_flux_mean_dist_2[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_sq_exp_argsort = np.argsort(gp_sq_exp_flux_mean_dist_2)\n",
    "gp_sq_exp_trim_25_idx = gp_sq_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_sq_exp_flux_mean_dist_2[gp_sq_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_32_argsort = np.argsort(gp_matern_32_flux_mean_dist_2)\n",
    "gp_matern_32_trim_25_idx = gp_matern_32_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_32_flux_mean_dist_2[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_52_argsort = np.argsort(gp_matern_52_flux_mean_dist_2)\n",
    "gp_matern_52_trim_25_idx = gp_matern_52_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_52_flux_mean_dist_2[gp_matern_52_trim_25_idx]))\n",
    "\n",
    "nn_flux_u_argsort = np.argsort(nn_flux_u_mean_dist_2)\n",
    "nn_flux_u_trim_25_idx = nn_flux_u_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_u_mean_dist_2[nn_flux_u_trim_25_idx]))\n",
    "\n",
    "nn_flux_2d_argsort = np.argsort(nn_flux_2d_mean_dist_2)\n",
    "nn_flux_2d_trim_25_idx = nn_flux_2d_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_2d_mean_dist_2[nn_flux_2d_trim_25_idx]))\n",
    "\n",
    "li_flux_argsort = np.argsort(li_flux_mean_dist_2)\n",
    "li_flux_trim_25_idx = li_flux_argsort[6250:-6250]\n",
    "print(np.mean(li_flux_mean_dist_2[li_flux_trim_25_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_spec_2 = np.mean(gp_exp_flux_results, axis=0)\n",
    "gp_sq_exp_flux_mean_spec_2 = np.mean(gp_sq_exp_flux_results, axis=0)\n",
    "nn_flux_u_mean_spec_2 = np.mean(nn_flux_u_results, axis=0)\n",
    "nn_flux_2d_mean_spec_2 = np.mean(nn_flux_2d_results, axis=0)\n",
    "li_flux_mean_spec_2 = np.mean(li_flux_results, axis=0)\n",
    "gp_matern_32_flux_mean_spec_2 = np.mean(gp_matern_32_flux_results, axis=0)\n",
    "gp_matern_52_flux_mean_spec_2 = np.mean(gp_matern_52_flux_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_300 = np.where(new_pca_obj.wavelengths >= 299.)[0][0]\n",
    "idx_1200 = np.where(new_pca_obj.wavelengths <= 1200.)[0][-1]+1\n",
    "print(np.mean(gp_exp_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_sq_exp_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_32_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_52_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(nn_flux_u_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(nn_flux_2d_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(li_flux_mean_spec_2[idx_300:idx_1200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with artificial filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "gp_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_sq_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_32_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_52_flux_results = np.zeros((25000, 6431))\n",
    "\n",
    "training_colors_full = []\n",
    "training_coeffs_full = []\n",
    "training_eigenspectra = []\n",
    "training_meanspec = []\n",
    "\n",
    "test_colors_full = []\n",
    "test_spectra_full = []\n",
    "test_coeffs_full = []\n",
    "test_exp_params = []\n",
    "test_sq_exp_params = []\n",
    "test_matern_32_params = []\n",
    "test_matern_52_params = []\n",
    "distances_all = []\n",
    "\n",
    "test_flux_orig = []\n",
    "flux_errors_full = []\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 99.\n",
    "max_wavelen = 2400.\n",
    "n_colors = 9\n",
    "n_comps = 9\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(training_colors)\n",
    "    distance, idx = nbrs.kneighbors(test_colors)\n",
    "    distances_all.append(np.ravel(distance))\n",
    "    \n",
    "    #print 'Gaussian Process Results'\n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, new_bandpass_dict)\n",
    "    gp_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((gp_spec.reconstruct_spectra(n_comps) - test_fluxes)/test_fluxes))#, \n",
    "    test_exp_params.append(gp_spec.params)\n",
    "    \n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('sq_exp', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, new_bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_sq_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))#, \n",
    "    test_sq_exp_params.append(gp_spec.params)\n",
    "        \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_32', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, new_bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_32_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_32_params.append(gp_spec.params)\n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_52', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, new_bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_52_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_52_params.append(gp_spec.params)\n",
    "    \n",
    "    training_colors_full.append(colors)\n",
    "    test_colors_full.append(test_colors)\n",
    "\n",
    "test_colors_full = np.array(test_colors_full)\n",
    "\n",
    "training_colors_full = np.array(training_colors_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating overall means\")\n",
    "\n",
    "gp_exp_flux_mean = np.mean(gp_exp_flux_results)\n",
    "#nn_flux_u_mean = np.mean(nn_flux_u_results)\n",
    "gp_sq_exp_flux_mean = np.mean(gp_sq_exp_flux_results)\n",
    "#nn_flux_2d_mean = np.mean(nn_flux_2d_results)\n",
    "#nn_flux_2u_mean = np.mean(nn_flux_2u_results)\n",
    "#nn_flux_4d_mean = np.mean(nn_flux_4d_results)\n",
    "#nn_flux_4u_mean = np.mean(nn_flux_4u_results)\n",
    "#li_flux_mean = np.mean(li_flux_results)\n",
    "gp_matern_32_flux_mean = np.mean(gp_matern_32_flux_results)\n",
    "gp_matern_52_flux_mean = np.mean(gp_matern_52_flux_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_sq_exp_flux_mean)\n",
    "print(gp_exp_flux_mean)\n",
    "#print(nn_flux_u_mean)\n",
    "#print(nn_flux_2d_mean)\n",
    "#print(li_flux_mean)\n",
    "print(gp_matern_32_flux_mean)\n",
    "print(gp_matern_52_flux_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_spec_3 = np.mean(gp_exp_flux_results, axis=0)\n",
    "gp_sq_exp_flux_mean_spec_3 = np.mean(gp_sq_exp_flux_results, axis=0)\n",
    "gp_matern_32_flux_mean_spec_3 = np.mean(gp_matern_32_flux_results, axis=0)\n",
    "gp_matern_52_flux_mean_spec_3 = np.mean(gp_matern_52_flux_results, axis=0)\n",
    "nn_flux_u_mean_spec_3 = np.mean(nn_flux_u_results, axis=0)\n",
    "li_flux_mean_spec_3 = np.mean(li_flux_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_300 = np.where(new_pca_obj.wavelengths >= 299.)[0][0]\n",
    "idx_1200 = np.where(new_pca_obj.wavelengths <= 1200.)[0][-1]+1\n",
    "print(np.mean(gp_exp_flux_mean_spec_3[idx_300:idx_1200]))\n",
    "print(np.mean(gp_sq_exp_flux_mean_spec_3[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_32_flux_mean_spec_3[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_52_flux_mean_spec_3[idx_300:idx_1200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_dist_3 = np.mean(gp_exp_flux_results, axis=1)\n",
    "gp_sq_exp_flux_mean_dist_3 = np.mean(gp_sq_exp_flux_results, axis=1)\n",
    "nn_flux_u_mean_dist_3 = np.mean(nn_flux_u_results, axis=1)\n",
    "#nn_flux_2d_mean_dist_3 = np.mean(nn_flux_2d_results, axis=1)\n",
    "li_flux_mean_dist_3 = np.mean(li_flux_results, axis=1)\n",
    "gp_matern_32_flux_mean_dist_3 = np.mean(gp_matern_32_flux_results, axis=1)\n",
    "gp_matern_52_flux_mean_dist_3 = np.mean(gp_matern_52_flux_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_exp_argsort = np.argsort(gp_exp_flux_mean_dist_3)\n",
    "gp_exp_trim_25_idx = gp_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_exp_flux_mean_dist_3[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_sq_exp_argsort = np.argsort(gp_sq_exp_flux_mean_dist_3)\n",
    "gp_sq_exp_trim_25_idx = gp_sq_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_sq_exp_flux_mean_dist_3[gp_sq_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_32_argsort = np.argsort(gp_matern_32_flux_mean_dist_3)\n",
    "gp_matern_32_trim_25_idx = gp_matern_32_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_32_flux_mean_dist_3[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_52_argsort = np.argsort(gp_matern_52_flux_mean_dist_3)\n",
    "gp_matern_52_trim_25_idx = gp_matern_52_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_52_flux_mean_dist_3[gp_matern_52_trim_25_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_axis_bgcolor('white') \n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "ax.set_xlabel('Wavelength (nm)', size=32)\n",
    "ax.set_ylabel('Ratio of Mean Fractional Residuals', size=32)\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22)\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_32_flux_mean_spec_2/nn_flux_u_mean_spec_3, label='GP with Matern-3/2 / NN', lw=4)\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_32_flux_mean_spec_2/li_flux_mean_spec_3, label='GP with Matern-3/2 / Linear', lw=4)\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('Only training with LSST filters', size=24)\n",
    "plt.hlines(1.0, 99, 2400, colors='k', linestyles='dashed', lw=6)\n",
    "plt.xlim(99, 2400)\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_32_flux_mean_spec_3/nn_flux_u_mean_spec_3, label='GP with Matern-3/2 / NN', lw=4)\n",
    "plt.plot(new_pca_obj.wavelengths, gp_matern_32_flux_mean_spec_3/li_flux_mean_spec_3, label='GP with Matern-3/2 / Linear', lw=4)\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('With additional training filters', size=24)\n",
    "plt.hlines(1.0, 99, 2400, colors='k', linestyles='dashed', lw=6)\n",
    "plt.xlim(99, 2400)\n",
    "plt.ylim(0, 2)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at distances from nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "distances_all = []\n",
    "\n",
    "test_flux_orig = []\n",
    "flux_errors_full = []\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 99.\n",
    "max_wavelen = 2400.\n",
    "n_colors = 9\n",
    "n_comps = 9\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(training_colors)\n",
    "    distance, idx = nbrs.kneighbors(test_colors)\n",
    "    distances_all.append(np.ravel(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_distances = np.ravel(distances_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 25\n",
    "bin_vals, gp_matern_52_dist_results = calc_dist_bins(use_distances, gp_matern_52_flux_mean_dist, n_bins)\n",
    "bin_vals, nn_u_dist_results = calc_dist_bins(use_distances, nn_flux_u_mean_dist, n_bins)\n",
    "bin_vals, nn_2d_dist_results = calc_dist_bins(use_distances, nn_flux_2d_mean_dist, n_bins)\n",
    "bin_vals, li_dist_results = calc_dist_bins(use_distances, li_flux_mean_dist, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 25\n",
    "bin_vals, gp_matern_32_dist_results_3 = calc_dist_bins(use_distances, gp_matern_32_flux_mean_dist_3, n_bins)\n",
    "bin_vals, nn_u_dist_results_3 = calc_dist_bins(use_distances, nn_flux_u_mean_dist_3, n_bins)\n",
    "bin_vals, li_dist_results_3 = calc_dist_bins(use_distances, li_flux_mean_dist_3, n_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,12))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_axis_bgcolor('white') \n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "ax.set_ylabel('Ratio of Mean Fractional Residuals', size=32)\n",
    "ax.set_xlabel('Distance in mags to nearest neighbor', size=32)\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22)\n",
    "\n",
    "fig.add_subplot(2,1,1)\n",
    "\n",
    "plt.plot(bin_vals[:-1], mean_dist_results(gp_matern_52_dist_results)/mean_dist_results(nn_2d_dist_results), label='GP with Matern-5/2 / 2 NN', lw=8)\n",
    "plt.plot(bin_vals[:-1], mean_dist_results(gp_matern_52_dist_results)/mean_dist_results(li_dist_results), label='GP with Matern-5/2 / LI', lw=8)\n",
    "plt.xlim(0, 0.6)\n",
    "plt.ylim(0, 2.)\n",
    "plt.hlines(1.0, 0.0, 0.6, linestyles='dashed', lw=6)\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('Ratio of Residual Errors in Test 1', size=32)\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "\n",
    "plt.plot(bin_vals[:-1], mean_dist_results(gp_matern_32_dist_results_3)/mean_dist_results(nn_u_dist_results_3), label='GP with Matern-3/2 / NN', lw=8)\n",
    "plt.plot(bin_vals[:-1], mean_dist_results(gp_matern_32_dist_results_3)/mean_dist_results(li_dist_results_3), label='GP with Matern-3/2 / LI', lw=8)\n",
    "plt.xlim(0, 0.6)\n",
    "plt.ylim(0, 2.)\n",
    "plt.hlines(1.0, 0.0, 0.6, linestyles='dashed', lw=6)\n",
    "plt.legend(fontsize=22)\n",
    "plt.title('Ratio of Residual Errors in Test 3', size=32)\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins = np.histogram(use_distances, bins=bin_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(n[:12])/np.sum(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Narrowband filters test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = ['F344N', 'F502N', 'F658N', 'F892N']\n",
    "narrow_band_dict = {}\n",
    "total_wavelengths = []\n",
    "for filt_name in filters:\n",
    "    narrow_band = np.genfromtxt('narrowband_filters/HST_ACS_HRC.%s.dat' % filt_name, unpack=True)\n",
    "    narrow_band[0] /= 10. # Convert to nanometers\n",
    "    total_wavelengths.append(narrow_band[0])\n",
    "    narrow_band_dict[filt_name] = narrow_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wavelengths = [x for y in total_wavelengths for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_bandpasses = []\n",
    "for filt_name in filters:\n",
    "    bandpass = np.zeros(len(total_wavelengths))\n",
    "    min_idx = np.where(total_wavelengths == narrow_band_dict[filt_name][0][0])[0][0]\n",
    "    max_idx = np.where(total_wavelengths == narrow_band_dict[filt_name][0][-1])[0][0]\n",
    "    bandpass[min_idx:max_idx+1] = narrow_band_dict[filt_name][1]\n",
    "    narrow_bandpasses.append(Bandpass(wavelen=np.array(total_wavelengths), sb=bandpass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_bandpass_dict = BandpassDict(narrow_bandpasses, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "li_flux_results = np.zeros((25000, 6071))\n",
    "nn_flux_u_results = np.zeros((25000, 6071))\n",
    "#nn_flux_2u_results = np.zeros((25000, 6071))\n",
    "nn_flux_2d_results = np.zeros((25000, 6071))\n",
    "#nn_flux_4u_results = np.zeros((25000, 6071))\n",
    "#nn_flux_4d_results = np.zeros((25000, 6071))\n",
    "gp_exp_flux_results = np.zeros((25000, 6071))\n",
    "gp_sq_exp_flux_results = np.zeros((25000, 6071))\n",
    "gp_matern_32_flux_results = np.zeros((25000, 6071))\n",
    "gp_matern_52_flux_results = np.zeros((25000, 6071))\n",
    "\n",
    "training_colors_full = []\n",
    "training_coeffs_full = []\n",
    "training_eigenspectra = []\n",
    "training_meanspec = []\n",
    "\n",
    "test_colors_full = []\n",
    "test_exp_params = []\n",
    "test_sq_exp_params = []\n",
    "test_matern_32_params = []\n",
    "test_matern_52_params = []\n",
    "distances_all = []\n",
    "\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 299.\n",
    "max_wavelen = 1200.\n",
    "n_colors = 3\n",
    "n_comps = 9\n",
    "\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(training_colors)\n",
    "    distance, idx = nbrs.kneighbors(test_colors)\n",
    "    distances_all.append(np.ravel(distance))\n",
    "    \n",
    "    #print 'Linear Interp'\n",
    "    li_spec, li_colors = linear_interpolation_spectra(colors, test_colors, new_pca_obj.spec_list_orig, \n",
    "                                                      bandpass_dict, min_wavelen, max_wavelen)\n",
    "    li_flux_results[i*50:(i+1)*50] = np.abs(np.array((li_spec - test_fluxes)/test_fluxes))\n",
    "    \n",
    "    #print 'Nearest Neighbor Results'\n",
    "    nn_obj = esp.nearestNeighborEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    nn_spec = nn_obj.nn_predict(1)\n",
    "    nn_flux_u_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "\n",
    "    #nn_spec = nn_obj.nn_predict(2)\n",
    "    #nn_flux_2u_results.append(np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes)))\n",
    "    nn_spec = nn_obj.nn_predict(2, knr_args=dict(weights='distance'))\n",
    "    nn_flux_2d_results[i*50:(i+1)*50] = np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes))\n",
    "\n",
    "    #nn_spec = nn_obj.nn_predict(4)\n",
    "    #nn_flux_4u_results.append(np.abs(np.array((nn_spec.reconstruct_spectra(10) - test_fluxes)/test_fluxes)))\n",
    "    #nn_spec = nn_obj.nn_predict(4, knr_args=dict(weights='distance'))\n",
    "    \n",
    "    #print 'Gaussian Process Results'\n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    gp_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((gp_spec.reconstruct_spectra(n_comps) - test_fluxes)/test_fluxes))#, \n",
    "    test_exp_params.append(gp_spec.params)\n",
    "    \n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('sq_exp', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_sq_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))#, \n",
    "    test_sq_exp_params.append(gp_spec.params)\n",
    "        \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_32', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_32_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_32_params.append(gp_spec.params)\n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_52', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, bandpass_dict)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_52_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_52_params.append(gp_spec.params)\n",
    "    \n",
    "    training_colors_full.append(colors)\n",
    "    test_colors_full.append(test_colors)\n",
    "\n",
    "\n",
    "test_colors_full = np.array(test_colors_full)\n",
    "\n",
    "training_colors_full = np.array(training_colors_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating overall means\")\n",
    "\n",
    "gp_exp_flux_mean_nb = np.mean(gp_exp_flux_results)\n",
    "nn_flux_u_mean_nb = np.mean(nn_flux_u_results)\n",
    "gp_sq_exp_flux_mean_nb = np.mean(gp_sq_exp_flux_results)\n",
    "nn_flux_2d_mean_nb = np.mean(nn_flux_2d_results)\n",
    "li_flux_mean_nb = np.mean(li_flux_results)\n",
    "gp_matern_32_flux_mean_nb = np.mean(gp_matern_32_flux_results)\n",
    "gp_matern_52_flux_mean_nb = np.mean(gp_matern_52_flux_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gp_exp_flux_mean_nb)\n",
    "print(gp_sq_exp_flux_mean_nb)\n",
    "print(gp_matern_32_flux_mean_nb)\n",
    "print(gp_matern_52_flux_mean_nb)\n",
    "print(nn_flux_u_mean_nb)\n",
    "print(nn_flux_2d_mean_nb)\n",
    "print(li_flux_mean_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_dist_nb = np.mean(gp_exp_flux_results, axis=1)\n",
    "gp_sq_exp_flux_mean_dist_nb = np.mean(gp_sq_exp_flux_results, axis=1)\n",
    "nn_flux_u_mean_dist_nb = np.mean(nn_flux_u_results, axis=1)\n",
    "nn_flux_2d_mean_dist_nb = np.mean(nn_flux_2d_results, axis=1)\n",
    "li_flux_mean_dist_nb = np.mean(li_flux_results, axis=1)\n",
    "gp_matern_32_flux_mean_dist_nb = np.mean(gp_matern_32_flux_results, axis=1)\n",
    "gp_matern_52_flux_mean_dist_nb = np.mean(gp_matern_52_flux_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_exp_argsort = np.argsort(gp_exp_flux_mean_dist_nb)\n",
    "gp_exp_trim_25_idx = gp_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_exp_flux_mean_dist_nb[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_sq_exp_argsort = np.argsort(gp_sq_exp_flux_mean_dist_nb)\n",
    "gp_sq_exp_trim_25_idx = gp_sq_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_sq_exp_flux_mean_dist_nb[gp_sq_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_32_argsort = np.argsort(gp_matern_32_flux_mean_dist_nb)\n",
    "gp_matern_32_trim_25_idx = gp_matern_32_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_32_flux_mean_dist_nb[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_52_argsort = np.argsort(gp_matern_52_flux_mean_dist_nb)\n",
    "gp_matern_52_trim_25_idx = gp_matern_52_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_52_flux_mean_dist_nb[gp_matern_52_trim_25_idx]))\n",
    "\n",
    "nn_flux_u_argsort = np.argsort(nn_flux_u_mean_dist_nb)\n",
    "nn_flux_u_trim_25_idx = nn_flux_u_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_u_mean_dist_nb[nn_flux_u_trim_25_idx]))\n",
    "\n",
    "nn_flux_2d_argsort = np.argsort(nn_flux_2d_mean_dist_nb)\n",
    "nn_flux_2d_trim_25_idx = nn_flux_2d_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_2d_mean_dist_nb[nn_flux_2d_trim_25_idx]))\n",
    "\n",
    "li_flux_argsort = np.argsort(li_flux_mean_dist_nb)\n",
    "li_flux_trim_25_idx = li_flux_argsort[6250:-6250]\n",
    "print(np.mean(li_flux_mean_dist_nb[li_flux_trim_25_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_bandpasses.insert(0, blue_bandpass_3)\n",
    "narrow_bandpasses.insert(0, blue_bandpass_1)\n",
    "narrow_bandpasses.append(bandpass_dict['y'])\n",
    "narrow_bandpasses.append(red_bandpass_2)\n",
    "narrow_bandpasses.append(red_bandpass_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "narrow_bandpass_dict_training = BandpassDict(narrow_bandpasses, ['blue_1', 'blue_3', filters[0], filters[1],\n",
    "                                                                 filters[2], filters[3], 'y', 'red_2', 'red_4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2314)\n",
    "\n",
    "li_flux_results = np.zeros((25000, 6431))\n",
    "nn_flux_u_results = np.zeros((25000, 6431))\n",
    "nn_flux_2d_results = np.zeros((25000, 6431))\n",
    "gp_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_sq_exp_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_32_flux_results = np.zeros((25000, 6431))\n",
    "gp_matern_52_flux_results = np.zeros((25000, 6431))\n",
    "\n",
    "training_colors_full = []\n",
    "training_coeffs_full = []\n",
    "training_eigenspectra = []\n",
    "training_meanspec = []\n",
    "\n",
    "test_colors_full = []\n",
    "test_spectra_full = []\n",
    "test_coeffs_full = []\n",
    "test_exp_params = []\n",
    "test_sq_exp_params = []\n",
    "test_matern_32_params = []\n",
    "test_matern_52_params = []\n",
    "test_var = []\n",
    "distances_all = []\n",
    "\n",
    "test_flux_orig = []\n",
    "flux_errors_full = []\n",
    "\n",
    "total_flagged = 0\n",
    "n_runs = 500\n",
    "min_wavelen = 99.\n",
    "max_wavelen = 2400.\n",
    "n_colors = 8\n",
    "n_comps = 9\n",
    "for i in range(n_runs):\n",
    "    if i % 20 == 0:\n",
    "        print('Run %i' % i)\n",
    "    \n",
    "    if os.path.exists('results'):\n",
    "        shutil.rmtree('results')\n",
    "    \n",
    "    training_colors, training_list, training_names, test_list, test_names, \\\n",
    "    test_fluxes, test_colors = choose_training_and_test_set(pca_obj, \n",
    "                                                            bandpass_dict, min_wavelen, max_wavelen)\n",
    "    \n",
    "    new_pca_obj = esp.pcaSED()\n",
    "    new_pca_obj.spec_list_orig = training_list\n",
    "    new_pca_obj.PCA(comps=n_comps, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "    \n",
    "    colors = training_colors\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=1).fit(training_colors)\n",
    "    distance, idx = nbrs.kneighbors(test_colors)\n",
    "    distances_all.append(np.ravel(distance))\n",
    "    \n",
    "    #print 'Gaussian Process Results'\n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, narrow_bandpass_dict_training)\n",
    "    gp_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((gp_spec.reconstruct_spectra(n_comps) - test_fluxes)/test_fluxes))#, \n",
    "    test_exp_params.append(gp_spec.params)\n",
    "    \n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('sq_exp', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, narrow_bandpass_dict_training)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_sq_exp_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))#, \n",
    "    test_sq_exp_params.append(gp_spec.params)\n",
    "        \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_32', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, narrow_bandpass_dict_training)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_32_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_32_params.append(gp_spec.params)\n",
    "    \n",
    "    gp_obj = esp.gaussianProcessEstimate(new_pca_obj, bandpass_dict, test_colors)\n",
    "    gp_kernel = gp_obj.define_kernel('matern_52', 1.0e-3, 1.0e-2, n_colors)\n",
    "    gp_spec = gp_obj.gp_predict(gp_kernel, narrow_bandpass_dict_training)\n",
    "    recon_spectra = gp_spec.reconstruct_spectra(n_comps)\n",
    "    gp_matern_52_flux_results[i*50:(i+1)*50] = np.abs(np.array((recon_spectra - test_fluxes)/test_fluxes))\n",
    "    test_matern_52_params.append(gp_spec.params)\n",
    "    \n",
    "    training_colors_full.append(colors)\n",
    "    test_colors_full.append(test_colors)\n",
    "\n",
    "test_colors_full = np.array(test_colors_full)\n",
    "\n",
    "training_colors_full = np.array(training_colors_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating overall means\")\n",
    "\n",
    "gp_exp_flux_mean_nb_2 = np.mean(gp_exp_flux_results)\n",
    "nn_flux_u_mean_nb_2 = np.mean(nn_flux_u_results)\n",
    "gp_sq_exp_flux_mean_nb_2 = np.mean(gp_sq_exp_flux_results)\n",
    "nn_flux_2d_mean_nb_2 = np.mean(nn_flux_2d_results)\n",
    "li_flux_mean_nb_2 = np.mean(li_flux_results)\n",
    "gp_matern_32_flux_mean_nb_2 = np.mean(gp_matern_32_flux_results)\n",
    "gp_matern_52_flux_mean_nb_2 = np.mean(gp_matern_52_flux_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gp_exp_flux_mean_nb_2)\n",
    "print(gp_sq_exp_flux_mean_nb_2)\n",
    "print(gp_matern_32_flux_mean_nb_2)\n",
    "print(gp_matern_52_flux_mean_nb_2)\n",
    "print(nn_flux_u_mean_nb_2)\n",
    "print(nn_flux_2d_mean_nb_2)\n",
    "print(li_flux_mean_nb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_spec_2 = np.mean(gp_exp_flux_results, axis=0)\n",
    "gp_sq_exp_flux_mean_spec_2 = np.mean(gp_sq_exp_flux_results, axis=0)\n",
    "nn_flux_u_mean_spec_2 = np.mean(nn_flux_u_results, axis=0)\n",
    "nn_flux_2d_mean_spec_2 = np.mean(nn_flux_2d_results, axis=0)\n",
    "li_flux_mean_spec_2 = np.mean(li_flux_results, axis=0)\n",
    "gp_matern_32_flux_mean_spec_2 = np.mean(gp_matern_32_flux_results, axis=0)\n",
    "gp_matern_52_flux_mean_spec_2 = np.mean(gp_matern_52_flux_results, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx_300 = np.where(new_pca_obj.wavelengths >= 299.)[0][0]\n",
    "idx_1200 = np.where(new_pca_obj.wavelengths <= 1200.)[0][-1]+1\n",
    "print(np.mean(gp_exp_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_sq_exp_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_32_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(gp_matern_52_flux_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(nn_flux_u_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(nn_flux_2d_mean_spec_2[idx_300:idx_1200]))\n",
    "print(np.mean(li_flux_mean_spec_2[idx_300:idx_1200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating mean spectra\")\n",
    "\n",
    "gp_exp_flux_mean_dist_nb_2 = np.mean(gp_exp_flux_results, axis=1)\n",
    "gp_sq_exp_flux_mean_dist_nb_2 = np.mean(gp_sq_exp_flux_results, axis=1)\n",
    "nn_flux_u_mean_dist_nb_2 = np.mean(nn_flux_u_results, axis=1)\n",
    "nn_flux_2d_mean_dist_nb_2 = np.mean(nn_flux_2d_results, axis=1)\n",
    "li_flux_mean_dist_nb_2 = np.mean(li_flux_results, axis=1)\n",
    "gp_matern_32_flux_mean_dist_nb_2 = np.mean(gp_matern_32_flux_results, axis=1)\n",
    "gp_matern_52_flux_mean_dist_nb_2 = np.mean(gp_matern_52_flux_results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_exp_argsort = np.argsort(gp_exp_flux_mean_dist_nb_2)\n",
    "gp_exp_trim_25_idx = gp_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_exp_flux_mean_dist_nb_2[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_sq_exp_argsort = np.argsort(gp_sq_exp_flux_mean_dist_nb_2)\n",
    "gp_sq_exp_trim_25_idx = gp_sq_exp_argsort[6250:-6250]\n",
    "print(np.mean(gp_sq_exp_flux_mean_dist_nb_2[gp_sq_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_32_argsort = np.argsort(gp_matern_32_flux_mean_dist_nb_2)\n",
    "gp_matern_32_trim_25_idx = gp_matern_32_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_32_flux_mean_dist_nb_2[gp_exp_trim_25_idx]))\n",
    "\n",
    "gp_matern_52_argsort = np.argsort(gp_matern_52_flux_mean_dist_nb_2)\n",
    "gp_matern_52_trim_25_idx = gp_matern_52_argsort[6250:-6250]\n",
    "print(np.mean(gp_matern_52_flux_mean_dist_nb_2[gp_matern_52_trim_25_idx]))\n",
    "\n",
    "nn_flux_u_argsort = np.argsort(nn_flux_u_mean_dist_nb_2)\n",
    "nn_flux_u_trim_25_idx = nn_flux_u_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_u_mean_dist_nb_2[nn_flux_u_trim_25_idx]))\n",
    "\n",
    "nn_flux_2d_argsort = np.argsort(nn_flux_2d_mean_dist_nb_2)\n",
    "nn_flux_2d_trim_25_idx = nn_flux_2d_argsort[6250:-6250]\n",
    "print(np.mean(nn_flux_2d_mean_dist_nb_2[nn_flux_2d_trim_25_idx]))\n",
    "\n",
    "li_flux_argsort = np.argsort(li_flux_mean_dist_nb_2)\n",
    "li_flux_trim_25_idx = li_flux_argsort[6250:-6250]\n",
    "print(np.mean(li_flux_mean_dist_nb_2[li_flux_trim_25_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometric Redshift Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create LePhare formatted catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load catalog (To request catalog email author)\n",
    "esp_test_cat = pd.read_csv('esp_test_cat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output catalog in LePhare format\n",
    "esp_test_cat['context'] = 63\n",
    "cols = esp_test_cat.columns.tolist()\n",
    "print(cols)\n",
    "\n",
    "lephare_cols = cols[2:] + [cols[1]] + [cols[0]]\n",
    "print(lephare_cols)\n",
    "\n",
    "lephare_cat = esp_test_cat[lephare_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write LePhare cat to file\n",
    "lephare_cat.to_csv('esp_lephare_cat.in', sep=' ', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create template sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1255)\n",
    "rand_sed_nums = np.random.choice(len(pca_obj.spec_list_orig), \n",
    "                                 size=60,\n",
    "                                 replace=False)\n",
    "template_set = []\n",
    "for sed_num in rand_sed_nums:\n",
    "    template_set.append(pca_obj.spec_list_orig[sed_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BC03 templates\n",
    "template_folder = 'photoz_template_set'\n",
    "os.mkdir(template_folder)\n",
    "os.mkdir(str(template_folder + '/ESP_10'))\n",
    "sed_names = []\n",
    "for sed_obj in template_set[:10]:\n",
    "    new_sed_obj = Sed()\n",
    "    new_sed_obj.setSED(wavelen=10.*sed_obj.wavelen, flambda=0.1*sed_obj.flambda)\n",
    "    new_sed_obj.writeSED(str(template_folder + '/ESP_10/' + sed_obj.name[:-3] + '.sed'))\n",
    "    sed_names.append('ESP_10/' + sed_obj.name[:-3] + '.sed')\n",
    "np.savetxt(str(template_folder + '/ESP_10/' + 'seds.list'), sed_names, fmt=['%s'])\n",
    "os.mkdir(str(template_folder + '/ESP_60'))\n",
    "sed_names = []\n",
    "for sed_obj in template_set[:60]:\n",
    "    new_sed_obj = Sed()\n",
    "    new_sed_obj.setSED(wavelen=10.*sed_obj.wavelen, flambda=0.1*sed_obj.flambda)\n",
    "    new_sed_obj.writeSED(str(template_folder + '/ESP_60/' + sed_obj.name[:-3] + '.sed'))\n",
    "    sed_names.append('ESP_60/' + sed_obj.name[:-3] + '.sed')\n",
    "np.savetxt(str(template_folder + '/ESP_60/' + 'seds.list'), sed_names, fmt=['%s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pca_obj = esp.pcaSED()\n",
    "new_pca_obj.spec_list_orig = template_set[:10]\n",
    "min_wavelen = 99.\n",
    "max_wavelen = 2400.\n",
    "new_pca_obj.PCA(comps=9, minWavelen=min_wavelen, maxWavelen=max_wavelen)\n",
    "esp_cat_bandpass_dict = BandpassDict.loadTotalBandpassesFromFiles(bandpassDir = 'photoz_bandpasses/')    \n",
    "colors = []\n",
    "for spec_num in range(10):\n",
    "    \n",
    "    test_sed = Sed()\n",
    "    test_sed.setSED(wavelen=new_pca_obj.spec_list_orig[spec_num].wavelen,\n",
    "                    flambda=new_pca_obj.spec_list_orig[spec_num].flambda)\n",
    "        \n",
    "    test_mags = esp_cat_bandpass_dict.magListForSed(test_sed)\n",
    "        \n",
    "    test_colors = [test_mags[x] - test_mags[x+1] for x in range(len(test_mags)-1)]\n",
    "    colors.append(test_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster catalog to find where we should estimate spectra\n",
    "from sklearn.cluster import KMeans\n",
    "esp_cat_colors = np.array([esp_test_cat['sdss_u'] - esp_test_cat['sdss_g'],\n",
    "                           esp_test_cat['sdss_g'] - esp_test_cat['sdss_r'],\n",
    "                           esp_test_cat['sdss_r'] - esp_test_cat['sdss_i'],\n",
    "                           esp_test_cat['sdss_i'] - esp_test_cat['sdss_z'],\n",
    "                           esp_test_cat['sdss_z'] - esp_test_cat['ps_y']]).T\n",
    "kmeans = KMeans(n_clusters=50, random_state=1428).fit(esp_cat_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_colors = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photoz_train_dict = BandpassDict([\n",
    "                                  blue_bandpass_1, blue_bandpass_3, \n",
    "                                  #blue_bandpass_3, blue_bandpass_4,\n",
    "                                  esp_cat_bandpass_dict['u'], esp_cat_bandpass_dict['g'], \n",
    "                                  esp_cat_bandpass_dict['r'], esp_cat_bandpass_dict['i'], esp_cat_bandpass_dict['z'], \n",
    "                                  esp_cat_bandpass_dict['y'], #red_bandpass_1, red_bandpass_2, \n",
    "                                  red_bandpass_2, red_bandpass_4\n",
    "                                 ],\n",
    "                                ['blue_1', #'blue_2', \n",
    "                                 'blue_3', #'blue_4', \n",
    "                                 'u', 'g', 'r', 'i', 'z', 'y', \n",
    "                                 'red_2',#'red_2', \n",
    "                                 'red_4', #'red_4'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_obj = esp.gaussianProcessEstimate(new_pca_obj, esp_cat_bandpass_dict, interp_colors)\n",
    "gp_kernel = gp_obj.define_kernel('exp', 1.0e-1, 1.0e-2, 9)\n",
    "gp_spec = gp_obj.gp_predict(gp_kernel, photoz_train_dict)\n",
    "gp_spectra = gp_spec.reconstruct_spectra(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(str(template_folder + '/ESP_EXP_KERNEL'))\n",
    "sed_names = []\n",
    "for sed_obj in template_set[:10]:\n",
    "    new_sed_obj = Sed()\n",
    "    new_sed_obj.setSED(wavelen=10.*sed_obj.wavelen, flambda=0.1*sed_obj.flambda)\n",
    "    new_sed_obj.writeSED(str(template_folder + '/ESP_EXP_KERNEL/' + sed_obj.name[:-3] + '.sed'))\n",
    "    sed_names.append('ESP_EXP_KERNEL/' + sed_obj.name[:-3] + '.sed')\n",
    "spec_on = 0\n",
    "for sed_obj in gp_spectra:\n",
    "    new_sed_obj = Sed()\n",
    "    new_sed_obj.setSED(wavelen=10.*new_pca_obj.wavelengths, \n",
    "                       flambda=0.1*sed_obj)\n",
    "    new_sed_obj.writeSED(str(template_folder + '/ESP_EXP_KERNEL/esp_' + str(spec_on) + '.sed'))\n",
    "    sed_names.append('ESP_EXP_KERNEL/esp_%i.sed' % spec_on)\n",
    "    spec_on+=1\n",
    "#np.savetxt(str(template_folder + '/ESP_EXP_KERNEL/' + 'seds.list'), sed_names, fmt=['%s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LePhare output\n",
    "template_10 = np.genfromtxt('esp_10.out', usecols=[1], names=['z_est_10'])\n",
    "template_60 = np.genfromtxt('esp_60.out', usecols=[1,22], names=['z_est_60', 'z_true'])\n",
    "template_exp_kernel = np.genfromtxt('esp_exp_kernel.out', usecols=[1], names=['z_est_exp_kernel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_results = pd.DataFrame()\n",
    "template_results['z_est_10'] = template_10['z_est_10']\n",
    "template_results['z_est_60'] = template_60['z_est_60']\n",
    "template_results['z_true'] = template_60['z_true']\n",
    "template_results['z_est_exp_kernel'] = template_exp_kernel['z_est_exp_kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_bins(z_est, z_true, z_max, n_bins):\n",
    "    delta_z = (z_true - z_est) / (1. + z_true)\n",
    "    bin_vals = [(float(i)/n_bins)*z_max for i in range(n_bins)]\n",
    "    bin_vals.append(float(z_max))\n",
    "    idx_sort = z_true.argsort()\n",
    "    delta_z_sort = delta_z[idx_sort]\n",
    "    z_true_sort = z_true[idx_sort]\n",
    "    idx_bins = z_true_sort.searchsorted(bin_vals)\n",
    "    delta_z_binned = [delta_z_sort[idx_bins[i]:idx_bins[i+1]] for i in range(n_bins)]\n",
    "    return delta_z_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import trim_mean\n",
    "def photo_z_bias(z_est, z_true, z_max, n_bins):\n",
    "    delta_z_binned = calc_bins(z_est, z_true, z_max, n_bins)\n",
    "    bias_results = []\n",
    "    for delta_z_data in delta_z_binned:\n",
    "        trimmed_mean = trim_mean(delta_z_data, .25)\n",
    "        bias_results.append(trimmed_mean)\n",
    "    return np.array(bias_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import trim_mean\n",
    "def photo_z_abs_bias(z_est, z_true, z_max, n_bins):\n",
    "    delta_z_binned = calc_bins(z_est, z_true, z_max, n_bins)\n",
    "    bias_results = []\n",
    "    for delta_z_data in delta_z_binned:\n",
    "        trimmed_mean = trim_mean(np.abs(delta_z_data), .25)\n",
    "        bias_results.append(trimmed_mean)\n",
    "    return np.array(bias_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_z_stdev(z_est, z_true, z_max, n_bins):\n",
    "    delta_z_binned = calc_bins(z_est, z_true, z_max, n_bins)\n",
    "    stdev_results = []\n",
    "    for delta_z_data in delta_z_binned:\n",
    "        bin_mean = np.mean(delta_z_data)\n",
    "        diffs = delta_z_data - bin_mean\n",
    "        diffs_sq_mean = np.mean(diffs**2.)\n",
    "        stdev_results.append(np.sqrt(diffs_sq_mean))\n",
    "    return np.array(stdev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_z_stdev_iqr(z_est, z_true, z_max, n_bins):\n",
    "    delta_z_binned = calc_bins(z_est, z_true, z_max, n_bins)\n",
    "    stdev_iqr_results = []\n",
    "    for delta_z_data in delta_z_binned:\n",
    "        bin_25 = np.percentile(delta_z_data, 25.)\n",
    "        bin_75 = np.percentile(delta_z_data, 75.)\n",
    "        diff = bin_75 - bin_25\n",
    "        stdev_iqr_results.append(diff/1.349)\n",
    "    return np.array(stdev_iqr_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_z_outlier_frac(z_est, z_true, z_max, n_bins):\n",
    "    stdev_iqr_results = photo_z_stdev_iqr(z_est, z_true, z_max, n_bins)\n",
    "    delta_z_binned = calc_bins(z_est, z_true, z_max, n_bins)\n",
    "    outlier_frac_results = []\n",
    "    for delta_z_data, stdev_iqr_val in zip(delta_z_binned, stdev_iqr_results):\n",
    "        if 3.*stdev_iqr_val < 0.06:\n",
    "            outlier_thresh = 0.06\n",
    "        else:\n",
    "            outlier_thresh = 3.*stdev_iqr_val\n",
    "        #print outlier_thresh, np.std(delta_z_data), len(delta_z_data), np.max(delta_z_data), np.min(delta_z_data)\n",
    "        total_bin_obj = float(len(delta_z_data))\n",
    "        outliers = np.where(np.abs(delta_z_data) > outlier_thresh)[0]\n",
    "        #print outliers\n",
    "        outlier_frac = len(outliers)/total_bin_obj\n",
    "        outlier_frac_results.append(outlier_frac)\n",
    "    return np.array(outlier_frac_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_max = 3.\n",
    "n_bins = 1\n",
    "\n",
    "delta_z_binned = calc_bins(template_results['z_est_10'], template_results['z_true'], \n",
    "                           z_max, n_bins)\n",
    "bin_counts = [len(bin_results) for bin_results in delta_z_binned]\n",
    "print(bin_counts)\n",
    "\n",
    "bias_results_10 = photo_z_bias(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "bias_results_60 = photo_z_bias(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "bias_results_exp = photo_z_bias(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "\n",
    "print(np.mean(bias_results_10))\n",
    "print(np.mean(bias_results_60))\n",
    "print(np.mean(bias_results_exp))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "stdev_results_10 = photo_z_stdev(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_results_60 = photo_z_stdev(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_results_exp = photo_z_stdev(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "print(np.mean(stdev_results_10))\n",
    "print(np.mean(stdev_results_60))\n",
    "print(np.mean(stdev_results_exp))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "stdev_iqr_results_10 = photo_z_stdev_iqr(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_iqr_results_60 = photo_z_stdev_iqr(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_iqr_results_exp = photo_z_stdev_iqr(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "\n",
    "print(np.mean(stdev_iqr_results_10))\n",
    "print(np.mean(stdev_iqr_results_60))\n",
    "print(np.mean(stdev_iqr_results_exp))\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "outlier_frac_results_10 = photo_z_outlier_frac(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "outlier_frac_results_60 = photo_z_outlier_frac(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "outlier_frac_results_exp = photo_z_outlier_frac(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "print(np.mean(outlier_frac_results_10))\n",
    "print(np.mean(outlier_frac_results_60))\n",
    "print(np.mean(outlier_frac_results_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bias', (0.0070834922179 - 0.0513398669249) / 0.0513398669249)\n",
    "print((0.013491192485 - 0.0513398669249) / 0.0513398669249)\n",
    "print('Standard Dev', (0.217399105893 - 0.278779776263) / 0.278779776263)\n",
    "print((0.173433673493 - 0.278779776263) / 0.278779776263)\n",
    "print('Standard Dev IQR', (0.0475990008076 - 0.12091776158) / 0.12091776158)\n",
    "print((0.036184609478 - 0.12091776158) / 0.12091776158)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "z_max = 3.0\n",
    "bin_width = 0.1\n",
    "n_bins = int(z_max/bin_width)\n",
    "bias_results_10 = photo_z_bias(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "bias_results_60 = photo_z_bias(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "bias_results_exp = photo_z_bias(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_10, label='10 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_60, label='60 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_exp, label='10 + Exp Kernel templates')\n",
    "plt.legend()\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "z_max = 3.0\n",
    "bin_width = 0.1\n",
    "n_bins = int(z_max/bin_width)\n",
    "stdev_results_10 = photo_z_stdev(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_results_60 = photo_z_stdev(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_results_exp = photo_z_stdev(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_10, label='10 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_60, label='60 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_exp, label='10 + Exp Kernel templates')\n",
    "plt.legend()\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Standard Deviation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "z_max = 3.0\n",
    "bin_width = 0.1\n",
    "n_bins = int(z_max/bin_width)\n",
    "stdev_iqr_results_10 = photo_z_stdev_iqr(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_iqr_results_60 = photo_z_stdev_iqr(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "stdev_iqr_results_exp = photo_z_stdev_iqr(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_10, label='10 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_60, label='60 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_exp, label='10 + Exp Kernel templates')\n",
    "plt.legend()\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Standard Deviation of IQR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "z_max = 3.0\n",
    "bin_width = 0.1\n",
    "n_bins = int(z_max/bin_width)\n",
    "outlier_frac_results_10 = photo_z_outlier_frac(template_results['z_est_10'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "outlier_frac_results_60 = photo_z_outlier_frac(template_results['z_est_60'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "outlier_frac_results_exp = photo_z_outlier_frac(template_results['z_est_exp_kernel'],\n",
    "                               template_results['z_true'], z_max, n_bins)\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_10, label='10 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_60, label='60 templates')\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_exp, label='10 + Exp Kernel templates')\n",
    "plt.legend()\n",
    "plt.xlabel('True Redshift')\n",
    "plt.ylabel('Fraction of Outliers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_results_max3 = template_results.query('z_true < 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 14))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.spines['top'].set_color('none')\n",
    "ax.spines['bottom'].set_color('none')\n",
    "ax.spines['left'].set_color('none')\n",
    "ax.spines['right'].set_color('none')\n",
    "ax.set_axis_bgcolor('white') \n",
    "ax.tick_params(labelcolor='w', top='off', bottom='off', left='off', right='off')\n",
    "mpl.rc('xtick', labelsize=22) \n",
    "mpl.rc('ytick', labelsize=22)\n",
    "\n",
    "fig.add_subplot(2,2,1)\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_10, label='10 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_60, label='60 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), bias_results_exp, label='10 + 50 Exp Kernel templates', lw=6)\n",
    "plt.xlabel('True Redshift', size=22)\n",
    "plt.ylabel('Bias', size=22)\n",
    "\n",
    "fig.add_subplot(2,2,2)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_10, label='10 BC03 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_60, label='60 BC03 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_results_exp, label='10 BC03 + 50 Exp Kernel templates', lw=6)\n",
    "plt.legend(fontsize=16)\n",
    "plt.xlabel('True Redshift', size=22)\n",
    "plt.ylabel('Standard Deviation', size=22)\n",
    "\n",
    "fig.add_subplot(2,2,3)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_10, label='10 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_60, label='60 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), stdev_iqr_results_exp, label='10 + 50 Exp Kernel templates', lw=6)\n",
    "plt.xlabel('True Redshift', size=22)\n",
    "plt.ylabel('Standard Deviation of IQR', size=22)\n",
    "\n",
    "fig.add_subplot(2,2,4)\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_10, label='10 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_60, label='60 templates', lw=6)\n",
    "plt.plot(np.arange(0,z_max,bin_width), outlier_frac_results_exp, label='10 + 50 Exp Kernel templates', lw=6)\n",
    "plt.xlabel('True Redshift', size=22)\n",
    "plt.ylabel('Fraction of Outliers', size=22)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('paper_plots_revised/fig_9.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = template_results_max3['z_true']\n",
    "y = template_results_max3['z_est_10']\n",
    "y_exp = template_results_max3['z_est_exp_kernel']\n",
    "\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.scatter(x, y, alpha=0.1)\n",
    "plt.plot(np.arange(0, 3.005, 0.01), np.arange(0, 3.005, 0.01), '--k')\n",
    "plt.ylim(-0.1, 5.55)\n",
    "plt.xlabel('z_true', size=32)\n",
    "plt.ylabel('z_phot', size=32)\n",
    "plt.title('10 BC03 Templates', size=32)\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.scatter(x, y_exp, alpha=0.1)\n",
    "plt.plot(np.arange(0, 3.005, 0.01), np.arange(0, 3.005, 0.01), '--k')\n",
    "plt.ylim(-0.1, 5.55)\n",
    "plt.xlabel('z_true', size=32)\n",
    "plt.ylabel('z_phot', size=32)\n",
    "plt.title('10 + 50 Exp Kernel Templates', size=32)\n",
    "#plt.savefig('paper_plots_revised/fig_11.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing spectrum degeneracies in color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_nm = pca_obj.spec_list_orig[0].wavelen\n",
    "test_idx = np.where((wave_nm <= 2400.) & (wave_nm >= 99.))\n",
    "wave_nm_test = wave_nm[np.where((wave_nm <= 2400.) & (wave_nm >= 99.))]\n",
    "\n",
    "test_colors = []\n",
    "test_fluxes = []\n",
    "for test_sed in pca_obj.spec_list_orig:\n",
    "        \n",
    "    test_fluxes.append(pca_obj.scale_spectrum(test_sed.flambda[test_idx]))\n",
    "        \n",
    "    test_mags = bandpass_dict.magListForSed(test_sed)\n",
    "        \n",
    "    colors = [test_mags[x] - test_mags[x+1] for x in range(len(test_mags)-1)]\n",
    "    test_colors.append(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=300).fit(test_colors)\n",
    "distance, idx = nbrs.kneighbors(test_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = .1\n",
    "num_in = []\n",
    "spec_near = []\n",
    "for spec_on in range(len(pca_obj.spec_list_orig)):\n",
    "    spec_near.append(idx[spec_on][np.where(distance[spec_on] < radius)[0][1:]])\n",
    "    num_in.append(len(spec_near[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat with added filters\n",
    "wave_nm = pca_obj.spec_list_orig[0].wavelen\n",
    "test_idx = np.where((wave_nm <= 2400.) & (wave_nm >= 99.))\n",
    "wave_nm_test = wave_nm[np.where((wave_nm <= 2400.) & (wave_nm >= 99.))]\n",
    "\n",
    "test_colors = []\n",
    "test_fluxes = []\n",
    "for test_sed in pca_obj.spec_list_orig:\n",
    "        \n",
    "    test_fluxes.append(pca_obj.scale_spectrum(test_sed.flambda[test_idx]))\n",
    "        \n",
    "    test_mags = new_bandpass_dict.magListForSed(test_sed)\n",
    "        \n",
    "    colors = [test_mags[x] - test_mags[x+1] for x in range(len(test_mags)-1)]\n",
    "    test_colors.append(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=300).fit(test_colors)\n",
    "distance, idx = nbrs.kneighbors(test_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_in = []\n",
    "spec_near_new = []\n",
    "for spec_on in range(len(pca_obj.spec_list_orig)):\n",
    "    spec_near_new.append(idx[spec_on][np.where(distance[spec_on] < radius)[0][1:]])\n",
    "    num_in.append(len(spec_near[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just redefine to make plot nice\n",
    "new_bandpass_dict = BandpassDict([\n",
    "                                  blue_bandpass_1, blue_bandpass_3, \n",
    "                                  #blue_bandpass_3, blue_bandpass_4,\n",
    "                                  bandpass_dict['u'], bandpass_dict['g'], \n",
    "                                  bandpass_dict['r'], bandpass_dict['i'], bandpass_dict['z'], \n",
    "                                  bandpass_dict['y'], #red_bandpass_1, red_bandpass_2, \n",
    "                                  red_bandpass_2, red_bandpass_4\n",
    "                                 ],\n",
    "                                ['Blue 1', #'blue_2', \n",
    "                                 'Blue 2', #'blue_4', \n",
    "                                 'u', 'g', 'r', 'i', 'z', 'y', \n",
    "                                 'Red 1',#'red_2', \n",
    "                                 'Red 2', #'red_4'\n",
    "                                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on = 8 # Pick test spectrum\n",
    "fig = plt.figure(figsize=(14,16))\n",
    "fig.add_subplot(2,1,1)\n",
    "for near_flux in spec_near[test_on][::-1]:\n",
    "    plt.plot(wave_nm_test, test_fluxes[near_flux]-test_fluxes[test_on])\n",
    "off_set = 0.0\n",
    "for bp, bp_colors in zip(['u', 'g', 'r', 'i', 'z', 'y'], ['purple', 'blue', 'green', 'yellow', 'orange', 'red']):\n",
    "    wavelen_bp = bandpass_dict[bp].wavelen[np.where(bandpass_dict[bp].sb > 0.)]\n",
    "    plt.plot(wavelen_bp, np.ones(len(wavelen_bp))*.0004+off_set, lw=8, c=bp_colors, label=str('LSST'+bp))\n",
    "    off_set += 0.00006\n",
    "mpl.rcParams['xtick.major.size'] = 15\n",
    "mpl.rcParams['xtick.major.width'] = 3\n",
    "mpl.rcParams['xtick.minor.size'] = 15\n",
    "mpl.rcParams['xtick.minor.width'] = 3\n",
    "\n",
    "plt.legend(fontsize=22)\n",
    "\n",
    "plt.ylabel('Flux Difference', size=22)\n",
    "plt.title('LSST Filters Only, Nearest Neighbors within %.2f mag radius' % radius, size=22)\n",
    "\n",
    "plt.ylim(-0.0017, 0.001)\n",
    "plt.xlim(75., 2405.)\n",
    "\n",
    "fig.add_subplot(2,1,2)\n",
    "for near_flux in spec_near_new[test_on]:\n",
    "    plt.plot(wave_nm_test, test_fluxes[near_flux]-test_fluxes[test_on])\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 15\n",
    "mpl.rcParams['xtick.major.width'] = 3\n",
    "mpl.rcParams['xtick.minor.size'] = 15\n",
    "mpl.rcParams['xtick.minor.width'] = 3\n",
    "\n",
    "off_set = 0.0\n",
    "for bp, bp_colors in zip(['Blue 1', 'Blue 2', 'u', 'g', 'r', 'i', 'z', 'y', 'Red 1', 'Red 2'], \n",
    "                         ['black', 'gray', 'purple', 'blue', 'green', 'yellow', 'orange', 'red', 'indianred', 'brown']):\n",
    "    wavelen_bp = new_bandpass_dict[bp].wavelen[np.where(new_bandpass_dict[bp].sb > 0.)]\n",
    "    if len(bp) < 2:\n",
    "        bp_label = str('LSST'+bp)\n",
    "    else:\n",
    "        bp_label = str('Top Hat '+bp)\n",
    "    plt.plot(wavelen_bp, np.ones(len(wavelen_bp))*-.00072-off_set, lw=8, c=bp_colors, label=bp_label)\n",
    "    off_set += 0.00006\n",
    "\n",
    "plt.xlabel('Wavelength (nm)', size=22)\n",
    "plt.ylabel('Flux Difference', size=22)\n",
    "\n",
    "plt.title('LSST + 4 Top Hat Filters, Nearest Neighbors within %.2f mag radius' % radius, size=22)\n",
    "\n",
    "plt.ylim(-0.0017, 0.001)\n",
    "plt.xlim(75., 2405.)\n",
    "plt.legend(fontsize=22, ncol=2)\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig('paper_plots_revised/fig_12.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
